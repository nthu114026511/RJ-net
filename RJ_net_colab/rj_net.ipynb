{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6a6b8f3",
   "metadata": {},
   "source": [
    "# RJ-net: Reaction-Jacobian Network for Reaction-Diffusion-Convection Systems\n",
    "\n",
    "本筆記本實現了基於物理的神經網路（PINN）求解反應-擴散-對流系統：\n",
    "\n",
    "$$\\rho_t + \\nabla \\cdot (\\rho \\vec{u}) = \\Delta \\rho + \\sum r_i$$\n",
    "\n",
    "## 核心方程\n",
    "\n",
    "1. **密度更新**: $\\rho^{n+1} = \\frac{\\rho_0 + R^{n+1}}{J^{n+1}}$\n",
    "2. **速度場**: $u^{n+1} = u_{NN}(\\rho^n)$\n",
    "3. **反應率**: $r^{n+1} = r_{NN}(\\rho^n)$\n",
    "4. **反應累積**: $R^{n+1} = R^n + \\Delta t \\cdot r^n$\n",
    "5. **Jacobian**: $J^{n+1} = J^n + \\Delta t [(\\nabla \\cdot u) J^n - u \\cdot \\nabla J]$\n",
    "\n",
    "## 測試問題: Fisher-KPP 方程\n",
    "\n",
    "$$\\rho_t = \\Delta \\rho + k^+ \\rho - k^- \\rho^2$$\n",
    "\n",
    "其中 $k^+ \\rho - k^- \\rho^2$ 是 logistic 反應項。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480d720",
   "metadata": {},
   "source": [
    "# --- 1. Environment setup ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6182070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "project_root = '/content/drive/My Drive/RJ_net_colab'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Install PyYAML to read the config file\n",
    "!pip install -q pyyaml\n",
    "\n",
    "print(\"✅ Setup complete. Google Drive is mounted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94342b1d",
   "metadata": {},
   "source": [
    "# --- Change to right directory ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa85de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/RJ_net_colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335b5b7c",
   "metadata": {},
   "source": [
    "# --- 2. Import necessary packages ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebef2d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import our custom plotter module\n",
    "import plotter\n",
    "\n",
    "print(\"✅ Packages imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc88c5cd",
   "metadata": {},
   "source": [
    "# --- 3. Neural Network Architecture ---\n",
    "\n",
    "我們定義兩個神經網路：\n",
    "1. **VelocityNet**: $u_{NN}(x, \\rho) \\rightarrow u$ - 預測速度場\n",
    "2. **ReactionNet**: $r_{NN}(x, \\rho) \\rightarrow r$ - 預測反應率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the configuration file\n",
    "with open('config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Create the output directory on Google Drive\n",
    "output_dir = config['paths']['output_dir']\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# --- Neural Network Definitions ---\n",
    "\n",
    "class VelocityNet(nn.Module):\n",
    "    \"\"\"Neural network to predict velocity field u(x, ρ).\"\"\"\n",
    "    def __init__(self, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_rho):\n",
    "        \"\"\"Input: [x, ρ], Output: u\"\"\"\n",
    "        return self.network(x_rho)\n",
    "\n",
    "\n",
    "class ReactionNet(nn.Module):\n",
    "    \"\"\"Neural network to predict reaction rate r(x, ρ).\"\"\"\n",
    "    def __init__(self, hidden_size=32):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(2, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, hidden_size), nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x_rho):\n",
    "        \"\"\"Input: [x, ρ], Output: r\"\"\"\n",
    "        return self.network(x_rho)\n",
    "\n",
    "\n",
    "def exact_reaction(rho, k_plus, k_minus):\n",
    "    \"\"\"Exact reaction term: r = k⁺ρ - k⁻ρ²\"\"\"\n",
    "    return k_plus * rho - k_minus * rho**2\n",
    "\n",
    "\n",
    "def initial_condition(x):\n",
    "    \"\"\"Initial condition: Gaussian bump or sine wave.\"\"\"\n",
    "    # Option 1: Gaussian\n",
    "    # return torch.exp(-50 * (x - 0.5)**2)\n",
    "    \n",
    "    # Option 2: Sine wave\n",
    "    return 0.5 * (1 + torch.sin(2 * torch.pi * x))\n",
    "\n",
    "\n",
    "print(f\"✅ Config loaded. Results will be saved to: {output_dir}\")\n",
    "print(f\"   Network architecture: {config['training']['hidden_size']} hidden units\")\n",
    "print(f\"   Reaction parameters: k⁺={config['physics']['k_plus']}, k⁻={config['physics']['k_minus']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25c7d7",
   "metadata": {},
   "source": [
    "# --- 4. Training Setup ---\n",
    "\n",
    "## 時間離散化方案\n",
    "\n",
    "對於每個時間步 $n = 0, 1, 2, \\ldots$:\n",
    "\n",
    "```python\n",
    "# 1. 預測速度和反應率\n",
    "u^{n+1} = VelocityNet(x, ρ^n)\n",
    "r^{n+1} = ReactionNet(x, ρ^n)\n",
    "\n",
    "# 2. 更新反應累積\n",
    "R^{n+1} = R^n + Δt · r^n\n",
    "\n",
    "# 3. 更新 Jacobian\n",
    "J^{n+1} = J^n · (1 + Δt · ∂u/∂x)\n",
    "\n",
    "# 4. 計算新的密度\n",
    "ρ^{n+1} = (ρ₀ + R^{n+1}) / J^{n+1}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924b4fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get parameters from the config object\n",
    "p = config['physics']\n",
    "t = config['training']\n",
    "DT = (p['t_max'] - p['t_min']) / (p['nt'] - 1)\n",
    "\n",
    "# Setup the training environment\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Create spatial grid\n",
    "x = torch.linspace(p['x_min'], p['x_max'], p['nx'], device=device).view(-1, 1)\n",
    "x.requires_grad = True\n",
    "\n",
    "# Time steps\n",
    "time_steps = torch.linspace(p['t_min'], p['t_max'], p['nt'], device=device)\n",
    "\n",
    "# Initialize networks\n",
    "velocity_net = VelocityNet(hidden_size=t['hidden_size']).to(device)\n",
    "reaction_net = ReactionNet(hidden_size=t['hidden_size']).to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(velocity_net.parameters()) + list(reaction_net.parameters()), \n",
    "    lr=t['learning_rate']\n",
    ")\n",
    "\n",
    "# Loss history\n",
    "loss_history = {\n",
    "    'total': [],\n",
    "    'pde': [],\n",
    "    'bc': [],\n",
    "    'reaction': []\n",
    "}\n",
    "\n",
    "print(f\"✅ Training setup complete.\")\n",
    "print(f\"   Spatial points: {p['nx']}\")\n",
    "print(f\"   Time steps: {p['nt']}\")\n",
    "print(f\"   dt = {DT:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a736ac",
   "metadata": {},
   "source": [
    "# --- 5. Training Loop ---\n",
    "\n",
    "## 損失函數\n",
    "\n",
    "1. **PDE 殘差**: $\\mathcal{L}_{PDE} = \\|\\rho_t - \\Delta \\rho - r(\\rho)\\|^2$\n",
    "2. **邊界條件**: $\\mathcal{L}_{BC} = \\|\\rho(0,t)\\|^2 + \\|\\rho(1,t)\\|^2$\n",
    "3. **初始條件**: $\\mathcal{L}_{IC} = \\|\\rho(x,0) - \\rho_0(x)\\|^2$\n",
    "4. **反應項**: $\\mathcal{L}_{reaction} = \\|r_{NN}(\\rho) - r_{exact}(\\rho)\\|^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f52b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting training...\\n\")\n",
    "\n",
    "for epoch in range(t['epochs']):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Initialize variables\n",
    "    rho_0 = initial_condition(x).detach()  # Initial density (constant)\n",
    "    rho_current = rho_0.clone()\n",
    "    J_current = torch.ones_like(x, device=device)  # Initial Jacobian = 1\n",
    "    R_current = torch.zeros_like(x, device=device)  # Initial reaction accumulation = 0\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    total_loss_pde = 0.0\n",
    "    total_loss_bc = 0.0\n",
    "    total_loss_reaction = 0.0\n",
    "    \n",
    "    # Time marching\n",
    "    for n in range(p['nt'] - 1):\n",
    "        # Prepare network input: [x, ρ]\n",
    "        net_input = torch.cat([x, rho_current], dim=1)\n",
    "        \n",
    "        # === 1. Predict velocity and reaction rate ===\n",
    "        u_current = velocity_net(net_input)\n",
    "        r_current = reaction_net(net_input)\n",
    "        \n",
    "        # === 2. Update R (reaction accumulation) ===\n",
    "        R_next = R_current + DT * r_current\n",
    "        \n",
    "        # === 3. Update J (Jacobian) ===\n",
    "        # Compute ∂u/∂x\n",
    "        du_dx = torch.autograd.grad(\n",
    "            u_current, x, \n",
    "            grad_outputs=torch.ones_like(u_current), \n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # J^{n+1} = J^n * (1 + Δt * ∂u/∂x)\n",
    "        # Simplified version (assuming u·∇J ≈ 0 for 1D)\n",
    "        J_next = J_current * (1 + DT * du_dx)\n",
    "        \n",
    "        # === 4. Update ρ (density) ===\n",
    "        # ρ^{n+1} = (ρ₀ + R^{n+1}) / J^{n+1}\n",
    "        rho_next = (rho_0 + R_next) / J_next\n",
    "        \n",
    "        # === 5. Compute PDE residual ===\n",
    "        # ρ_t ≈ (ρ^{n+1} - ρ^n) / Δt\n",
    "        rho_t = (rho_next - rho_current) / DT\n",
    "        \n",
    "        # Compute Laplacian: Δρ = ∂²ρ/∂x²\n",
    "        drho_dx = torch.autograd.grad(\n",
    "            rho_next, x, \n",
    "            grad_outputs=torch.ones_like(rho_next), \n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        d2rho_dx2 = torch.autograd.grad(\n",
    "            drho_dx, x, \n",
    "            grad_outputs=torch.ones_like(drho_dx), \n",
    "            create_graph=True\n",
    "        )[0]\n",
    "        \n",
    "        # Exact reaction term for comparison\n",
    "        r_exact = exact_reaction(rho_next, p['k_plus'], p['k_minus'])\n",
    "        \n",
    "        # PDE residual: ρ_t = Δρ + r(ρ)\n",
    "        pde_residual = rho_t - d2rho_dx2 - r_exact\n",
    "        loss_pde = torch.mean(pde_residual**2)\n",
    "        \n",
    "        # === 6. Boundary conditions ===\n",
    "        # Homogeneous Neumann BC: ∂ρ/∂x = 0 at boundaries\n",
    "        loss_bc = drho_dx[0]**2 + drho_dx[-1]**2\n",
    "        \n",
    "        # === 7. Reaction loss ===\n",
    "        # Encourage reaction network to learn the correct reaction term\n",
    "        loss_reaction = torch.mean((r_current - r_exact.detach())**2)\n",
    "        \n",
    "        # Accumulate losses\n",
    "        total_loss_pde += loss_pde\n",
    "        total_loss_bc += loss_bc\n",
    "        total_loss_reaction += loss_reaction\n",
    "        \n",
    "        # Update for next iteration (detach to avoid backprop through time)\n",
    "        rho_current = rho_next.detach()\n",
    "        rho_current.requires_grad = True\n",
    "        J_current = J_next.detach()\n",
    "        R_current = R_next.detach()\n",
    "    \n",
    "    # === 8. Total loss ===\n",
    "    total_loss = (\n",
    "        t['weight_pde'] * total_loss_pde + \n",
    "        t['weight_bc'] * total_loss_bc + \n",
    "        t['weight_reaction'] * total_loss_reaction\n",
    "    )\n",
    "    \n",
    "    # Backpropagation\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Record losses\n",
    "    loss_history['total'].append(total_loss.item())\n",
    "    loss_history['pde'].append(total_loss_pde.item())\n",
    "    loss_history['bc'].append(total_loss_bc.item())\n",
    "    loss_history['reaction'].append(total_loss_reaction.item())\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{t['epochs']}]\")\n",
    "        print(f\"  Total Loss: {total_loss.item():.6f}\")\n",
    "        print(f\"  PDE: {total_loss_pde.item():.6f}, BC: {total_loss_bc.item():.6f}, Reaction: {total_loss_reaction.item():.6f}\")\n",
    "\n",
    "print(\"\\n✅ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892df39c",
   "metadata": {},
   "source": [
    "# --- 6. Generate Results & Visualization ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6713c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Generating results and creating visualizations...\\n\")\n",
    "\n",
    "velocity_net.eval()\n",
    "reaction_net.eval()\n",
    "\n",
    "# Storage for histories\n",
    "rho_numerical_history = []\n",
    "R_history = []\n",
    "J_history = []\n",
    "u_history = []\n",
    "r_history = []\n",
    "\n",
    "# Initialize\n",
    "rho_0 = initial_condition(x).detach()\n",
    "rho_current = rho_0.clone()\n",
    "J_current = torch.ones_like(x, device=device)\n",
    "R_current = torch.zeros_like(x, device=device)\n",
    "\n",
    "# Store initial state\n",
    "rho_numerical_history.append(rho_current.cpu().numpy())\n",
    "R_history.append(R_current.cpu().numpy())\n",
    "J_history.append(J_current.cpu().numpy())\n",
    "\n",
    "# Time marching (evaluation mode)\n",
    "with torch.no_grad():\n",
    "    for n in range(p['nt'] - 1):\n",
    "        net_input = torch.cat([x, rho_current], dim=1)\n",
    "        \n",
    "        # Predict\n",
    "        u_current = velocity_net(net_input)\n",
    "        r_current = reaction_net(net_input)\n",
    "        \n",
    "        # Update R\n",
    "        R_next = R_current + DT * r_current\n",
    "        \n",
    "        # Update J (需要計算梯度)\n",
    "        x_temp = x.clone()\n",
    "        x_temp.requires_grad = True\n",
    "        rho_temp = rho_current.clone()\n",
    "        net_input_temp = torch.cat([x_temp, rho_temp], dim=1)\n",
    "        u_temp = velocity_net(net_input_temp)\n",
    "        \n",
    "        du_dx = torch.autograd.grad(\n",
    "            u_temp, x_temp, \n",
    "            grad_outputs=torch.ones_like(u_temp), \n",
    "            create_graph=False\n",
    "        )[0]\n",
    "        \n",
    "        J_next = J_current * (1 + DT * du_dx)\n",
    "        \n",
    "        # Update ρ\n",
    "        rho_next = (rho_0 + R_next) / J_next\n",
    "        \n",
    "        # Store\n",
    "        rho_numerical_history.append(rho_next.cpu().numpy())\n",
    "        R_history.append(R_next.cpu().numpy())\n",
    "        J_history.append(J_next.cpu().numpy())\n",
    "        u_history.append(u_current.cpu().numpy())\n",
    "        r_history.append(r_current.cpu().numpy())\n",
    "        \n",
    "        # Update for next iteration\n",
    "        rho_current = rho_next\n",
    "        J_current = J_next\n",
    "        R_current = R_next\n",
    "\n",
    "# Convert to numpy\n",
    "x_np = x.cpu().detach().numpy()\n",
    "time_steps_np = time_steps.cpu().numpy()\n",
    "\n",
    "print(\"✅ Solution generated.\")\n",
    "print(f\"   Final ρ range: [{rho_numerical_history[-1].min():.4f}, {rho_numerical_history[-1].max():.4f}]\")\n",
    "print(f\"   Final R range: [{R_history[-1].min():.4f}, {R_history[-1].max():.4f}]\")\n",
    "print(f\"   Final J range: [{J_history[-1].min():.4f}, {J_history[-1].max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbe449",
   "metadata": {},
   "source": [
    "# --- 7. Create Plots ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6447dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss history\n",
    "plotter.plot_loss(loss_history, config, f\"{output_dir}/loss.png\")\n",
    "\n",
    "# Plot comparison\n",
    "plotter.plot_comparison(x_np, rho_numerical_history, config, f\"{output_dir}/comparison.png\")\n",
    "\n",
    "# Plot R and J evolution\n",
    "plotter.plot_reaction_jacobian(x_np, R_history, J_history, config, f\"{output_dir}/reaction_jacobian.png\")\n",
    "\n",
    "# Create animation\n",
    "plotter.create_animation(\n",
    "    x_np, rho_numerical_history, time_steps_np, config, \n",
    "    f\"{output_dir}/animation.gif\",\n",
    "    R_history=R_history, J_history=J_history\n",
    ")\n",
    "\n",
    "print(\"\\n✅ All visualizations complete!\")\n",
    "print(f\"\\nResults saved to: {output_dir}\")\n",
    "print(\"  - loss.png: Training loss evolution\")\n",
    "print(\"  - comparison.png: Initial vs final states\")\n",
    "print(\"  - reaction_jacobian.png: R and J evolution\")\n",
    "print(\"  - animation.gif: Full time evolution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc205b",
   "metadata": {},
   "source": [
    "# --- 8. Additional Analysis ---\n",
    "\n",
    "分析學習到的速度場和反應率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02557fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot velocity and reaction rate at different times\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Select time indices for visualization\n",
    "time_indices = [0, len(u_history)//3, 2*len(u_history)//3, len(u_history)-1]\n",
    "\n",
    "for idx in time_indices:\n",
    "    if idx < len(u_history):\n",
    "        t_val = time_steps_np[idx+1]  # +1 because we didn't store initial u,r\n",
    "        axes[0, 0].plot(x_np, u_history[idx], label=f't={t_val:.2f}')\n",
    "        axes[0, 1].plot(x_np, r_history[idx], label=f't={t_val:.2f}')\n",
    "\n",
    "axes[0, 0].set_title('Velocity Field u(x,t)')\n",
    "axes[0, 0].set_xlabel('x')\n",
    "axes[0, 0].set_ylabel('u')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True)\n",
    "\n",
    "axes[0, 1].set_title('Reaction Rate r(x,t)')\n",
    "axes[0, 1].set_xlabel('x')\n",
    "axes[0, 1].set_ylabel('r')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True)\n",
    "\n",
    "# Compare learned reaction with exact reaction\n",
    "rho_test = torch.linspace(0, 1, 100, device=device).view(-1, 1)\n",
    "x_test = 0.5 * torch.ones_like(rho_test)\n",
    "net_input_test = torch.cat([x_test, rho_test], dim=1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    r_learned = reaction_net(net_input_test).cpu().numpy()\n",
    "    r_exact = exact_reaction(rho_test, p['k_plus'], p['k_minus']).cpu().numpy()\n",
    "\n",
    "rho_test_np = rho_test.cpu().numpy()\n",
    "axes[1, 0].plot(rho_test_np, r_exact, 'g-', linewidth=2, label='Exact: k⁺ρ - k⁻ρ²')\n",
    "axes[1, 0].plot(rho_test_np, r_learned, 'r--', linewidth=2, label='Learned r_NN(ρ)')\n",
    "axes[1, 0].set_title('Reaction Rate: Learned vs Exact')\n",
    "axes[1, 0].set_xlabel('ρ')\n",
    "axes[1, 0].set_ylabel('r(ρ)')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Mass conservation check: M(t) = ∫ρ dx\n",
    "mass_history = [np.trapz(rho, x_np.flatten()) for rho in rho_numerical_history]\n",
    "axes[1, 1].plot(time_steps_np, mass_history, 'b-', linewidth=2)\n",
    "axes[1, 1].set_title('Total Mass M(t) = ∫ρ dx')\n",
    "axes[1, 1].set_xlabel('t')\n",
    "axes[1, 1].set_ylabel('M(t)')\n",
    "axes[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/analysis.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Additional analysis complete!\")\n",
    "print(f\"   Mass conservation: M(0)={mass_history[0]:.4f}, M(T)={mass_history[-1]:.4f}\")\n",
    "print(f\"   Relative change: {abs(mass_history[-1] - mass_history[0])/mass_history[0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b68cc9a",
   "metadata": {},
   "source": [
    "# --- Summary ---\n",
    "\n",
    "## 實現的數學框架\n",
    "\n",
    "本筆記本成功實現了 RJ-net（Reaction-Jacobian Network）框架：\n",
    "\n",
    "1. **密度演化**: $\\rho^{n+1} = \\frac{\\rho_0 + R^{n+1}}{J^{n+1}}$\n",
    "2. **兩個神經網路**:\n",
    "   - VelocityNet: 學習速度場 $u(x, \\rho)$\n",
    "   - ReactionNet: 學習反應率 $r(x, \\rho)$\n",
    "3. **物理約束**: 通過 PDE 殘差確保解滿足反應-擴散-對流方程\n",
    "\n",
    "## 關鍵特點\n",
    "\n",
    "- ✅ Lagrangian-Eulerian 混合描述\n",
    "- ✅ 顯式追蹤反應累積 R(t)\n",
    "- ✅ Jacobian 演化 J(t)\n",
    "- ✅ 物理資訊神經網路（PINN）\n",
    "- ✅ 可處理複雜的反應-擴散-對流耦合系統\n",
    "\n",
    "## 未來改進方向\n",
    "\n",
    "1. 多物種反應系統：$\\vec{\\rho} = [\\rho_1, \\rho_2, \\ldots]$\n",
    "2. 2D/3D 擴展\n",
    "3. 適應性時間步長\n",
    "4. 更複雜的反應動力學（如 Michaelis-Menten）\n",
    "5. 實驗數據驅動的學習"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
